{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_table('./train.csv', sep = ',')\n",
    "data_test = pd.read_table('./test.csv', sep = ',')\n",
    "data_validation = pd.read_table('./validation.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_ortho(lon1, lat1, lon2, lat2):\n",
    "    R = 6377726\n",
    "    pi = np.pi\n",
    "    a = np.sin((lat1 - lat2)/2*pi/180)**2\n",
    "    b = np.cos(lat1*pi/180)*np.cos(lat2*pi/180)\n",
    "    c = np.sin((lon1- lon2)/2* pi/180)**2\n",
    "\n",
    "    dist = R * 2* np.arcsin( np.sqrt(a + b*c))\n",
    "    return dist\n",
    "\n",
    "\n",
    "class TrajDataSet(Dataset):\n",
    "    def __init__(self,  df, window, transform=None):\n",
    "        self.df = df.set_index(np.arange(len(df))) #reorder idx\n",
    "        self.window = window\n",
    "        self.start_idx = np.where([self.df.trip[i]==self.df.trip[i+self.window-1] for i in range(len(self.df)-self.window+1)])[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.start_idx)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        i = self.start_idx[idx]\n",
    "\n",
    "        # select variable of interest\n",
    "        traj = self.df.loc[i:i+self.window-1, ('lon', 'lat')]\n",
    "        traj = np.array(traj).T\n",
    "\n",
    "        # select coordinates\n",
    "        coord = self.df.loc[i:i+self.window-1, ('lon', 'lat')]\n",
    "        coord = np.array(coord).T\n",
    "        lon = np.vstack([coord[0] for i in range(traj.shape[1])])\n",
    "        lat = np.vstack([coord[1]  for i in range(traj.shape[1])])\n",
    "        dd = dist_ortho(lon, lat, lon.T, lat.T)\n",
    "\n",
    "        sample = (dd, dd)\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        dd, dd, = sample\n",
    "        dd, dd  = (torch.FloatTensor(dd), torch.FloatTensor(dd))\n",
    "        return (dd.unsqueeze(0), dd.unsqueeze(0))\n",
    "\n",
    "class Divide(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __init__(self, ratio):\n",
    "        self.ratio = ratio\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        dd, dd = sample\n",
    "        dd = dd/self.ratio\n",
    "        return (dd, dd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "window = 128\n",
    "batch_size = 64\n",
    "\n",
    "## reduce size dataset\n",
    "train_set = TrajDataSet(data_train, window, transform = transforms.Compose([Divide(12000), ToTensor()]))\n",
    "validation_set = TrajDataSet(data_validation, window, transform = transforms.Compose([Divide(12000), ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers = 0, shuffle = True, drop_last=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size, num_workers = 0, shuffle = True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.cnn_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pooling_1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size = 5, stride = 2, padding = 0, dilation = 1)\n",
    "        )\n",
    "\n",
    "        self.cnn_2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 16, kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pooling_2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size = 5, stride = 2, padding = 0, dilation = 1)\n",
    "        )\n",
    "\n",
    "        self.cnn_3 = nn.Sequential(\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64,  kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128,  kernel_size = 5, stride = 1, padding = 2, dilation = 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.pooling_3 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size = 8, stride = 2, padding = 0, dilation = 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.cnn_1(x)\n",
    "        out = self.pooling_1(out)\n",
    "        out = self.cnn_2(out)\n",
    "        out = self.pooling_2(out)\n",
    "#         out = self.cnn_3(out)\n",
    "#         out = self.pooling_3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "     \n",
    "        self.upsampling_3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size = 8, stride = 2, padding = 0, dilation = 1)\n",
    "        )\n",
    "        \n",
    "        self.cnn_3 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 64,  kernel_size = 5, stride = 1, padding = 4, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32,  kernel_size = 5, stride = 1, padding = 4, dilation = 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.upsampling_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 32, kernel_size = 5, stride = 2, padding = 0, dilation = 1)\n",
    "        )\n",
    "        \n",
    "        self.cnn_2 = nn.Sequential(\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 16,  kernel_size = 5, stride = 1, padding = 4, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 8,  kernel_size = 5, stride = 1, padding = 4, dilation = 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.upsampling_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 8, kernel_size = 5, stride = 2, padding = 0, dilation = 1)\n",
    "        )\n",
    "        \n",
    "        self.cnn_1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 4, kernel_size = 5, stride = 1, padding = 4, dilation = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 1,  kernel_size = 5, stride = 1, padding = 4, dilation = 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.upsampling_3(x)\n",
    "        out = self.cnn_3(out)\n",
    "        out = self.upsampling_2(out)\n",
    "        out = self.cnn_2(out)\n",
    "        out = self.upsampling_1(out)\n",
    "        out = self.cnn_1(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 29, 29])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sample\n",
    "x, y = next(iter(train_loader)) \n",
    "\n",
    "# Forward model\n",
    "encod = Encoder()\n",
    "decod = Decoder()\n",
    "\n",
    "out = encod(x)\n",
    "\n",
    "out.shape\n",
    "# decod(out).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "out = model.threshold(y)\n",
    "out = torch.sum(out, 2)\n",
    "\n",
    "out = torch.cat((out, x.squeeze(1)), 1)\n",
    "\n",
    "out_1 = model.cnn_input_1(out)\n",
    "out = model.pooling_1(out_1)\n",
    "out_2 = model.cnn_input_2(out)\n",
    "out = model.pooling_2(out_2)\n",
    "out = model.cnn_input_3(out)\n",
    "\n",
    "out = model.upconv_2(out)\n",
    "out = torch.cat((out, out_2), 1)\n",
    "out = model.cnn_output_2(out)\n",
    "\n",
    "out = model.upconv_1(out)\n",
    "out = torch.cat((out, out_1), 1)\n",
    "out = model.cnn_output_1(out)\n",
    "\n",
    "out.size()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
